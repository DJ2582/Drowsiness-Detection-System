{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1650,"status":"ok","timestamp":1651817609868,"user":{"displayName":"rutvik patel","userId":"10208618498044122931"},"user_tz":-330},"id":"Yx5EcA1L5ACm"},"outputs":[],"source":["import cv2\n","import dlib\n","from scipy.spatial import distance\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1651817611959,"user":{"displayName":"rutvik patel","userId":"10208618498044122931"},"user_tz":-330},"id":"1X5E_r139sm2"},"outputs":[],"source":["from google.colab.patches import cv2_imshow"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1651817612625,"user":{"displayName":"rutvik patel","userId":"10208618498044122931"},"user_tz":-330},"id":"d0l01MHw-vk4"},"outputs":[],"source":["from IPython.display import display, Javascript,HTML\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","\n","def record_video(filename):\n","  js=Javascript(\"\"\"\n","    async function recordVideo() {\n","      const options = { mimeType: \"video/webm; codecs=vp9\" };\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      const stopCapture = document.createElement(\"button\");\n","      \n","      capture.textContent = \"Start Recording\";\n","      capture.style.background = \"orange\";\n","      capture.style.color = \"white\";\n","\n","      stopCapture.textContent = \"Stop Recording\";\n","      stopCapture.style.background = \"red\";\n","      stopCapture.style.color = \"white\";\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      const recordingVid = document.createElement(\"video\");\n","      video.style.display = 'block';\n","\n","      const stream = await navigator.mediaDevices.getUserMedia({audio:true, video: true});\n","    \n","      let recorder = new MediaRecorder(stream, options);\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","\n","      video.srcObject = stream;\n","      video.muted = true;\n","\n","      await video.play();\n","\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      await new Promise((resolve) => {\n","        capture.onclick = resolve;\n","      });\n","      recorder.start();\n","      capture.replaceWith(stopCapture);\n","\n","      await new Promise((resolve) => stopCapture.onclick = resolve);\n","      recorder.stop();\n","      let recData = await new Promise((resolve) => recorder.ondataavailable = resolve);\n","      let arrBuff = await recData.data.arrayBuffer();\n","      \n","      // stop the stream and remove the video element\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","\n","      let binaryString = \"\";\n","      let bytes = new Uint8Array(arrBuff);\n","      bytes.forEach((byte) => {\n","        binaryString += String.fromCharCode(byte);\n","      })\n","    return btoa(binaryString);\n","    }\n","  \"\"\")\n","  try:\n","    display(js)\n","    data=eval_js('recordVideo({})')\n","    binary=b64decode(data)\n","    with open(filename,\"wb\") as video_file:\n","      video_file.write(binary)\n","    print(f\"Finished recording video at:{filename}\")\n","  except Exception as err:\n","    print(str(err))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":18013,"status":"ok","timestamp":1651817633105,"user":{"displayName":"rutvik patel","userId":"10208618498044122931"},"user_tz":-330},"id":"icR9i0d9-vg2","outputId":"c865bb00-30a4-4f96-d21f-d6a2252c9abe"},"outputs":[{"data":{"application/javascript":"\n    async function recordVideo() {\n      const options = { mimeType: \"video/webm; codecs=vp9\" };\n      const div = document.createElement('div');\n      const capture = document.createElement('button');\n      const stopCapture = document.createElement(\"button\");\n      \n      capture.textContent = \"Start Recording\";\n      capture.style.background = \"orange\";\n      capture.style.color = \"white\";\n\n      stopCapture.textContent = \"Stop Recording\";\n      stopCapture.style.background = \"red\";\n      stopCapture.style.color = \"white\";\n      div.appendChild(capture);\n\n      const video = document.createElement('video');\n      const recordingVid = document.createElement(\"video\");\n      video.style.display = 'block';\n\n      const stream = await navigator.mediaDevices.getUserMedia({audio:true, video: true});\n    \n      let recorder = new MediaRecorder(stream, options);\n      document.body.appendChild(div);\n      div.appendChild(video);\n\n      video.srcObject = stream;\n      video.muted = true;\n\n      await video.play();\n\n      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n      await new Promise((resolve) => {\n        capture.onclick = resolve;\n      });\n      recorder.start();\n      capture.replaceWith(stopCapture);\n\n      await new Promise((resolve) => stopCapture.onclick = resolve);\n      recorder.stop();\n      let recData = await new Promise((resolve) => recorder.ondataavailable = resolve);\n      let arrBuff = await recData.data.arrayBuffer();\n      \n      // stop the stream and remove the video element\n      stream.getVideoTracks()[0].stop();\n      div.remove();\n\n      let binaryString = \"\";\n      let bytes = new Uint8Array(arrBuff);\n      bytes.forEach((byte) => {\n        binaryString += String.fromCharCode(byte);\n      })\n    return btoa(binaryString);\n    }\n  ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Finished recording video at:test.mp4\n"]}],"source":["video_path = \"test.mp4\"\n","record_video(video_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BAMP_izr-vel"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1y0y4XKlNDQK15qOTFq2Z-k8YdoBQPz57"},"executionInfo":{"elapsed":21241,"status":"error","timestamp":1651760217624,"user":{"displayName":"rutvik patel","userId":"10208618498044122931"},"user_tz":-330},"id":"4dVKiiu_5DPb","outputId":"616d470b-e35b-4730-fa13-f4bd4983ed8f"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["def calculate_EAR(eye):\n","\tA = distance.euclidean(eye[1], eye[5])\n","\tB = distance.euclidean(eye[2], eye[4])\n","\tC = distance.euclidean(eye[0], eye[3])\n","\tear_aspect_ratio = (A+B)/(2.0*C)\n","\treturn ear_aspect_ratio\n","\n","# cap = cv2.VideoCapture('/content/drive/MyDrive/Colab Notebooks/facevideo.mp4')\n","cap = cv2.VideoCapture('test.mp4')\n","hog_face_detector = dlib.get_frontal_face_detector()\n","dlib_facelandmark = dlib.shape_predictor('/content/drive/MyDrive/Colab Notebooks/shape_predictor_68_face_landmarks.dat')\n","\n","while True:\n","    _, frame = cap.read()\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","    faces = hog_face_detector(gray)\n","    for face in faces:\n","\n","        face_landmarks = dlib_facelandmark(gray, face)\n","        leftEye = []\n","        rightEye = []\n","\n","        for n in range(36,42):\n","        \tx = face_landmarks.part(n).x\n","        \ty = face_landmarks.part(n).y\n","        \tleftEye.append((x,y))\n","        \tnext_point = n+1\n","        \tif n == 41:\n","        \t\tnext_point = 36\n","        \tx2 = face_landmarks.part(next_point).x\n","        \ty2 = face_landmarks.part(next_point).y\n","        \tcv2.line(frame,(x,y),(x2,y2),(0,255,0),1)\n","\n","        for n in range(42,48):\n","        \tx = face_landmarks.part(n).x\n","        \ty = face_landmarks.part(n).y\n","        \trightEye.append((x,y))\n","        \tnext_point = n+1\n","        \tif n == 47:\n","        \t\tnext_point = 42\n","        \tx2 = face_landmarks.part(next_point).x\n","        \ty2 = face_landmarks.part(next_point).y\n","        \tcv2.line(frame,(x,y),(x2,y2),(0,255,0),1)\n","\n","        left_ear = calculate_EAR(leftEye)\n","        right_ear = calculate_EAR(rightEye)\n","\n","        EAR = (left_ear+right_ear)/2\n","        EAR = round(EAR,2)\n","        if EAR<0.26:\n","        \tcv2.putText(frame,\"DROWSY\",(20,100),\n","        \t\tcv2.FONT_HERSHEY_SIMPLEX,3,(0,0,255),4)\n","        \t\n","        \tprint(\"Drowsy\")\n","        cv2.putText(frame,\"EAR: \"+str(EAR),(20,400),\n","          cv2.FONT_HERSHEY_SIMPLEX,2,(0,0,255),4)\n","        print(EAR)\n","\n","    cv2_imshow(frame)\n","\n","    key = cv2.waitKey(1)\n","    if key == 27:\n","        break\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GXl7rmwb55SC"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM0Dsz/MzV9P3bxTWnnNfE1","collapsed_sections":[],"mount_file_id":"1AOBBxQx6Ji7civcj_rGNkopKl8YJ-oo1","name":"drowsynessUsingDlib.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
